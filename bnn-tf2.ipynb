{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Neural Networks in Keras and TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.0.0b1\n",
      "  Using cached https://files.pythonhosted.org/packages/29/6c/2c9a5c4d095c63c2fb37d20def0e4f92685f7aee9243d6aae25862694fd1/tensorflow-2.0.0b1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: gast>=0.2.0 in /glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages (from tensorflow==2.0.0b1)\n",
      "Requirement already satisfied: six>=1.10.0 in /glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages (from tensorflow==2.0.0b1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages (from tensorflow==2.0.0b1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/u30073/.local/lib/python3.6/site-packages (from tensorflow==2.0.0b1)\n",
      "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /home/u30073/.local/lib/python3.6/site-packages (from tensorflow==2.0.0b1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages (from tensorflow==2.0.0b1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages (from tensorflow==2.0.0b1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages (from tensorflow==2.0.0b1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages (from tensorflow==2.0.0b1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages (from tensorflow==2.0.0b1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages (from tensorflow==2.0.0b1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /home/u30073/.local/lib/python3.6/site-packages (from tensorflow==2.0.0b1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/u30073/.local/lib/python3.6/site-packages (from tensorflow==2.0.0b1)\n",
      "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /home/u30073/.local/lib/python3.6/site-packages (from tensorflow==2.0.0b1)\n",
      "Requirement already satisfied: wheel>=0.26 in /glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages (from tensorflow==2.0.0b1)\n",
      "Requirement already satisfied: h5py in /glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow==2.0.0b1)\n",
      "Requirement already satisfied: setuptools in /home/u30073/.local/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow==2.0.0b1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0b1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0b1)\n",
      "Installing collected packages: tensorflow\n",
      "  Found existing installation: tensorflow 1.14.0\n",
      "    Uninstalling tensorflow-1.14.0:\n",
      "      Successfully uninstalled tensorflow-1.14.0\n",
      "\u001b[31mException:\n",
      "Traceback (most recent call last):\n",
      "  File \"/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/shutil.py\", line 420, in _rmtree_safe_fd\n",
      "    os.rmdir(name, dir_fd=topfd)\n",
      "OSError: [Errno 39] Directory not empty: 'framework'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/pip/basecommand.py\", line 215, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/pip/commands/install.py\", line 342, in run\n",
      "    prefix=options.prefix_path,\n",
      "  File \"/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/pip/req/req_set.py\", line 795, in install\n",
      "    requirement.commit_uninstall()\n",
      "  File \"/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/pip/req/req_install.py\", line 767, in commit_uninstall\n",
      "    self.uninstalled.commit()\n",
      "  File \"/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/pip/req/req_uninstall.py\", line 142, in commit\n",
      "    rmtree(self.save_dir)\n",
      "  File \"/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/pip/_vendor/retrying.py\", line 49, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "  File \"/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/pip/_vendor/retrying.py\", line 212, in call\n",
      "    raise attempt.get()\n",
      "  File \"/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/pip/_vendor/retrying.py\", line 247, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "  File \"/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/pip/_vendor/six.py\", line 686, in reraise\n",
      "    raise value\n",
      "  File \"/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/pip/_vendor/retrying.py\", line 200, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "  File \"/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/pip/utils/__init__.py\", line 102, in rmtree\n",
      "    onerror=rmtree_errorhandler)\n",
      "  File \"/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/shutil.py\", line 480, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/shutil.py\", line 418, in _rmtree_safe_fd\n",
      "    _rmtree_safe_fd(dirfd, fullname, onerror)\n",
      "  File \"/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/shutil.py\", line 418, in _rmtree_safe_fd\n",
      "    _rmtree_safe_fd(dirfd, fullname, onerror)\n",
      "  File \"/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/shutil.py\", line 418, in _rmtree_safe_fd\n",
      "    _rmtree_safe_fd(dirfd, fullname, onerror)\n",
      "  [Previous line repeated 4 more times]\n",
      "  File \"/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/shutil.py\", line 422, in _rmtree_safe_fd\n",
      "    onerror(os.rmdir, fullname, sys.exc_info())\n",
      "  File \"/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/pip/utils/__init__.py\", line 114, in rmtree_errorhandler\n",
      "    func(path)\n",
      "OSError: [Errno 39] Directory not empty: '/home/u30073/tmp/pip-p6dxq3hu-uninstall/home/u30073/.local/lib/python3.6/site-packages/tensorflow/python/framework'\u001b[0m\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tfp_nightly\n",
      "  Downloading https://files.pythonhosted.org/packages/65/b7/0c33cd9eb31cecb40ad723499df6f554acb3bc133a0743174954c22cb344/tfp_nightly-0.9.0.dev20190913-py2.py3-none-any.whl (2.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.6MB 285kB/s eta 0:00:01   6% |██▏                             | 174kB 17.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /home/u30073/.local/lib/python3.6/site-packages (from tfp_nightly)\n",
      "Requirement already satisfied: six>=1.10.0 in /glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages (from tfp_nightly)\n",
      "Requirement already satisfied: gast<0.3,>=0.2 in /glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages (from tfp_nightly)\n",
      "Requirement already satisfied: cloudpickle==1.1.1 in /home/u30073/.local/lib/python3.6/site-packages (from tfp_nightly)\n",
      "Requirement already satisfied: decorator in /glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages (from tfp_nightly)\n",
      "Installing collected packages: tfp-nightly\n",
      "Successfully installed tfp-nightly-0.9.0.dev20190913\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Installed kernelspec tf_prob in /home/u30073/.local/share/jupyter/kernels/tf_prob\n"
     ]
    }
   ],
   "source": [
    "! . activate base\n",
    "!pip install tensorflow==2.0.0b1 --user\n",
    "!pip install tfp_nightly --user\n",
    "!python -m ipykernel install --name tf_prob --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u30073/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/glob/intel-python/python3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#TODO: PUT RANDOM SEED FOR RESULT SECURING IN DEMOS\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version (expected = 2.0.0-beta1): 2.0.0-beta1\n",
      "TensorFlow Probability version (expected = 0.9.0-dev20190912): 0.9.0-dev20190913\n"
     ]
    }
   ],
   "source": [
    "print('TensorFlow version (expected = 2.0.0-beta1):', tf.__version__)\n",
    "print('TensorFlow Probability version (expected = 0.9.0-dev20190912):', tfp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X, theta = 1.0, axis = None):\n",
    "    \"\"\"\n",
    "    Compute the softmax of each element along an axis of X.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: ND-Array. Probably should be floats.\n",
    "    theta (optional): float parameter, used as a multiplier\n",
    "        prior to exponentiation. Default = 1.0\n",
    "    axis (optional): axis to compute values along. Default is the\n",
    "        first non-singleton axis.\n",
    "\n",
    "    Returns an array the same size as X. The result will sum to 1\n",
    "    along the specified axis.\n",
    "    \"\"\"\n",
    "\n",
    "    # make X at least 2d\n",
    "    y = np.atleast_2d(X)\n",
    "\n",
    "    # find axis\n",
    "    if axis is None:\n",
    "        axis = next(j[0] for j in enumerate(y.shape) if j[1] > 1)\n",
    "\n",
    "    # multiply y against the theta parameter,\n",
    "    y = y * float(theta)\n",
    "\n",
    "    # subtract the max for numerical stability\n",
    "    y = y - np.expand_dims(np.max(y, axis = axis), axis)\n",
    "\n",
    "    # exponentiate y\n",
    "    y = np.exp(y)\n",
    "\n",
    "    # take the sum along the specified axis\n",
    "    ax_sum = np.expand_dims(np.sum(y, axis = axis), axis)\n",
    "\n",
    "    # finally: divide elementwise\n",
    "    p = y / ax_sum\n",
    "\n",
    "    # flatten if X was 1D\n",
    "    if len(X.shape) == 1: p = p.flatten()\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are all set up, lets go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using MNIST dataset!\n",
      "X_train.shape = (60000, 28, 28, 1)\n",
      "y_train.shape = (60000, 10)\n",
      "X_test.shape = (10000, 28, 28, 1)\n",
      "y_test.shape = (10000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd2bc663160>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhB8IivADQf0bIHV3m9z7zF4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd2be45eef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "first, we load the dataset. We are trying to do it first with MNIST\n",
    "I've found this snippet somewhere in github\n",
    "\"\"\"\n",
    "\n",
    "#as we have 10 classes, I'm setting class number to 10\n",
    "class_nmr = 10\n",
    "\n",
    "print('We are using MNIST dataset!')\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "n_train = X_train.shape[0]\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, class_nmr)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, class_nmr)\n",
    "\n",
    "# Normalize data\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "print(\"X_train.shape =\", X_train.shape)\n",
    "print(\"y_train.shape =\", y_train.shape)\n",
    "print(\"X_test.shape =\", X_test.shape)\n",
    "print(\"y_test.shape =\", y_test.shape)\n",
    "\n",
    "plt.imshow(X_train[1026, :, :, 0], cmap='gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bayesian_bcnn_model(input_shape):\n",
    "    \n",
    "    \"\"\"\n",
    "    Here we use tf.keras.Model to use our graph as a Neural Network:\n",
    "    We select our input node as the net input, and the last node as our output (predict node).\n",
    "    Note that our model won't be compiled, as we are usign TF2.0 and will optimize it with\n",
    "    a custom @tf.function for loss and a @tf.function for train_step\n",
    "    Our input parameter is just the input shape, a tuple, for the input layer\n",
    "    \"\"\"\n",
    "    \n",
    "    model_in = tf.keras.layers.Input(shape=input_shape)\n",
    "    conv_1 = tfp.python.layers.Convolution2DFlipout(32, kernel_size=(3, 3), padding=\"same\", strides=2)\n",
    "    x = conv_1(model_in)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    conv_2 = tfp.python.layers.Convolution2DFlipout(64, kernel_size=(3, 3), padding=\"same\", strides=2)\n",
    "    x = conv_2(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    dense_1 = tfp.python.layers.DenseFlipout(512, activation='relu')\n",
    "    x = dense_1(x)\n",
    "    dense_2 = tfp.python.layers.DenseFlipout(10, activation=None)\n",
    "    model_out = dense_2(x)  # logits\n",
    "    model = tf.keras.Model(model_in, model_out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "here we are just instancing our model and setting up an Optimizer\n",
    "\"\"\"\n",
    "bcnn = build_bayesian_bcnn_model(X_train.shape[1:])\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this is our loss function: a sum of KL Divergence and Softmax crossentropy\n",
    "We use the @tf.function annotation becuase of TF2.0, and need no placeholders\n",
    "we get each loss and return its mean\n",
    "\"\"\"\n",
    "\n",
    "@tf.function\n",
    "def elbo_loss(labels, logits):\n",
    "    loss_en = tf.nn.softmax_cross_entropy_with_logits(labels, logits)\n",
    "    loss_kl = tf.keras.losses.KLD(labels, logits)\n",
    "    loss = tf.reduce_mean(tf.add(loss_en, loss_kl))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this is our train step with tf2.0, very ellegant:\n",
    "We do our flow of the tensors over the model recording its gradientes\n",
    "Then, our gradient tape to give us a list of the gradients of each parameter in relation of the loss\n",
    "we dan ask our previously instanced optimizer to apply those gradients to the variable\n",
    "It is cool to see that it works even with TensorFlow probability- probabilistic layers parameters\n",
    "\"\"\"\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = bcnn(X_train)\n",
    "        loss = elbo_loss(labels, logits)\n",
    "    gradients = tape.gradient(loss, bcnn.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, bcnn.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "def accuracy(preds, labels):\n",
    "    return np.mean(np.argmax(preds, axis=1) == np.argmax(y_train, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0: loss =  12.933 , accuracy =   0.118, time:  21.339\n",
      "Epoch: 1: loss =  15.430 , accuracy =   0.134, time:   9.556\n",
      "Epoch: 2: loss =   9.380 , accuracy =   0.184, time:   9.562\n",
      "Epoch: 3: loss =   9.176 , accuracy =   0.187, time:   9.762\n",
      "Epoch: 4: loss =   7.173 , accuracy =   0.203, time:   9.987\n",
      "Epoch: 5: loss =   4.073 , accuracy =   0.195, time:   9.707\n",
      "Epoch: 6: loss =   3.161 , accuracy =   0.208, time:   9.629\n",
      "Epoch: 7: loss =   2.578 , accuracy =   0.202, time:   9.631\n",
      "Epoch: 8: loss =   2.262 , accuracy =   0.229, time:   9.478\n",
      "Epoch: 9: loss =   2.123 , accuracy =   0.288, time:   9.761\n",
      "Epoch: 10: loss =   1.981 , accuracy =   0.404, time:   9.694\n",
      "Epoch: 11: loss =   1.786 , accuracy =   0.483, time:   9.536\n",
      "Epoch: 12: loss =   1.627 , accuracy =   0.562, time:   9.602\n",
      "Epoch: 13: loss =   1.381 , accuracy =   0.626, time:   9.644\n",
      "Epoch: 14: loss =   1.153 , accuracy =   0.684, time:   9.540\n",
      "Epoch: 15: loss =   0.980 , accuracy =   0.724, time:   9.593\n",
      "Epoch: 16: loss =   0.871 , accuracy =   0.735, time:   9.613\n",
      "Epoch: 17: loss =   0.805 , accuracy =   0.750, time:   9.765\n",
      "Epoch: 18: loss =   0.809 , accuracy =   0.777, time:   9.588\n",
      "Epoch: 19: loss =   0.697 , accuracy =   0.808, time:   9.694\n",
      "Epoch: 20: loss =   0.633 , accuracy =   0.823, time:   9.863\n",
      "Epoch: 21: loss =   0.587 , accuracy =   0.836, time:   9.672\n",
      "Epoch: 22: loss =   0.563 , accuracy =   0.845, time:   9.647\n",
      "Epoch: 23: loss =   0.540 , accuracy =   0.852, time:   9.565\n",
      "Epoch: 24: loss =   0.506 , accuracy =   0.864, time:   9.711\n",
      "Epoch: 25: loss =   0.473 , accuracy =   0.871, time:   9.705\n",
      "Epoch: 26: loss =   0.436 , accuracy =   0.876, time:   9.770\n",
      "Epoch: 27: loss =   0.427 , accuracy =   0.880, time:   9.752\n",
      "Epoch: 28: loss =   0.393 , accuracy =   0.885, time:   9.669\n",
      "Epoch: 29: loss =   0.384 , accuracy =   0.889, time:   9.663\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "in our train step we can see that it lasts more tha na normal CNN to converge\n",
    "on the other side, we can have the confidence interval for our predictions, which are \n",
    "wonderful in terms of taking sensitive predictions\n",
    "\"\"\"\n",
    "times = []\n",
    "for i in range(30):\n",
    "    tic = time.time()\n",
    "    loss = train_step(X_train, y_train)\n",
    "    preds = bcnn(X_train)\n",
    "    acc = accuracy(preds, y_train)\n",
    "    tac = time.time()\n",
    "    train_time = tac-tic\n",
    "    times.append(train_time)\n",
    "    print(\"Epoch: {}: loss = {:7.3f} , accuracy = {:7.3f}, time: {:7.3f}\".format(i, loss, acc, train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In TensorFlow 2.0.0b1 our train time mean was :  10.057, with std :   2.098\n",
      "\n",
      "However, by removing the outlier 1st time, our train time mean was :   9.668, with std :   0.105\n",
      "\n",
      "We conclude TensorFlow 2 has a longer time to start its variables, but then does it faster than TF1.14 Intel Optimzied (see other notebook)\n"
     ]
    }
   ],
   "source": [
    "### About the performance:\n",
    "\n",
    "mean = np.mean(times)\n",
    "std = np.std(times)\n",
    "print(\"In TensorFlow 2.0.0b1 our train time mean was : {:7.3f}, with std : {:7.3f}\".format(mean, std))\n",
    "\n",
    "no_outlier = times[1:]\n",
    "no_mean = np.mean(no_outlier)\n",
    "no_std = np.std(no_outlier)\n",
    "print(\"\\nHowever, by removing the outlier 1st time, our train time mean was : {:7.3f}, with std : {:7.3f}\".format(no_mean, no_std))\n",
    "print(\"\\nWe conclude TensorFlow 2 has a longer time to start its variables, but then does it faster than TF1.14 Intel Optimzied (see other notebook)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will illustrate our predictions and confidence intervals\n",
    "\n",
    "Those illustrative functions were taken from https://github.com/zhulingchen/tfp-tutorial/ repo, which had the tutorial (in Keras) that did let me learn how to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of recognizable samples: 9995\n",
      "Unrecognizable samples: [2488 3757 3846 4761 5735]\n",
      "Test accuracy on MNIST (recognizable samples): 0.8938469234617309\n",
      "Test accuracy on MNIST (unrecognizable samples): 0.0\n"
     ]
    }
   ],
   "source": [
    "n_mc_run = 50\n",
    "med_prob_thres = 0.20\n",
    "\n",
    "y_pred_logits_list = [bcnn(X_test) for _ in range(n_mc_run)]  # a list of predicted logits\n",
    "y_pred_prob_all = np.concatenate([softmax(y, axis=-1)[:, :, np.newaxis] for y in y_pred_logits_list], axis=-1)\n",
    "y_pred = [[int(np.median(y) >= med_prob_thres) for y in y_pred_prob] for y_pred_prob in y_pred_prob_all]\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "idx_valid = [any(y) for y in y_pred]\n",
    "print('Number of recognizable samples:', sum(idx_valid))\n",
    "\n",
    "idx_invalid = [not any(y) for y in y_pred]\n",
    "print('Unrecognizable samples:', np.where(idx_invalid)[0])\n",
    "\n",
    "print('Test accuracy on MNIST (recognizable samples):',\n",
    "      sum(np.equal(np.argmax(y_test[idx_valid], axis=-1), np.argmax(y_pred[idx_valid], axis=-1))) / len(y_test[idx_valid]))\n",
    "\n",
    "print('Test accuracy on MNIST (unrecognizable samples):',\n",
    "      sum(np.equal(np.argmax(y_test[idx_invalid], axis=-1), np.argmax(y_pred[idx_invalid], axis=-1))) / len(y_test[idx_invalid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7febb024b828>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAADn9JREFUeJzt3X2IVfedx/HP10TJg/0jpsaKYzNG\nJNklmLgZZKHNklCVtBFMISY1EGazwUmIgTWUkJAH6gOGEtLu5glBUdTQ2hp0NsaEWJHNpoElZJSl\nY32oElyrTnxAQRsMjea7f8xxmZq5v3Pn3nPvueP3/YIw957vPed+ueTj79x7Hn7m7gIQz4iyGwBQ\nDsIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCoK5v5ZmbG6YRAg7m7VfO6ukZ+M7vHzPaZ2QEz\ne7aebQFoLqv13H4zu0LSnyTNlHRY0qeS5rn77sQ6jPxAgzVj5J8u6YC7f+buf5X0G0lz6tgegCaq\nJ/wTJP15wPPD2bK/YWZdZtZjZj11vBeAgtXzg99guxbf2K139xWSVkjs9gOtpJ6R/7CkiQOet0k6\nWl87AJqlnvB/KmmKmU0ys1GSfiJpczFtAWi0mnf73f28mT0paaukKyStdvc/FtYZgIaq+VBfTW/G\nd36g4Zpykg+A4YvwA0ERfiAowg8ERfiBoAg/EFRTr+e/XN1yyy3J+sqVK5P1t99+O1l/7bXXhtwT\nkIeRHwiK8ANBEX4gKMIPBEX4gaAIPxAUh/qqZFb5QqmFCxcm1+3o6EjWX3jhhZp6AurByA8ERfiB\noAg/EBThB4Ii/EBQhB8IivADQXH33irNnj27Yu3dd99Nrtvb25usT506taaegMFw914ASYQfCIrw\nA0ERfiAowg8ERfiBoAg/EFRd1/Ob2UFJZyVdkHTe3dMXrg9jkydPrnndTZs2FdgJUIwibuZxt7uf\nLGA7AJqI3X4gqHrD75J+Z2Y7zKyriIYANEe9u/3fc/ejZnaDpG1mttfdPxr4guwfBf5hAFpMXSO/\nux/N/h6X1C1p+iCvWeHuHZfzj4HAcFRz+M3sWjP71sXHkmZJ2lVUYwAaq57d/nGSurNbWl8p6dfu\n/kEhXQFouJrD7+6fSbqtwF5a2owZM2pe96233iqwE1z09NNPJ+ttbW0Va6+//npy3QMHDtTU03DC\noT4gKMIPBEX4gaAIPxAU4QeCIvxAUNy6OzNx4sRkfceOHRVr+/btS6579913J+vnz59P1i9XI0ak\nx57nn38+WV+0aFHN29+7d29y3TvvvDNZP3mydS9k5dbdAJIIPxAU4QeCIvxAUIQfCIrwA0ERfiCo\nIu7ee1mYMGFCsj527NiKtV270vcwiXocP88zzzyTrC9ZsiRZ//LLL5P1V155pWJt7ty5yXW7u7uT\n9UceeSRZHw6XBDPyA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQHOfPdHZ2lt3CZemaa66pWOvqqm8W\nt1dffTVZf/HFFyvWdu7cmVw3b1r1hx56KFnPO0ehFTDyA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQ\nucf5zWy1pNmSjrv7rdmyMZJ+K6ld0kFJD7j76ca12XgjR46sed39+/cX2Mnl5cEHH6xYa29vT657\n9OjRZH3dunW1tCRJ+uCDD5L1DRs2JOvz589P1pcvX56snzhxIllvhmpG/jWS7rlk2bOStrv7FEnb\ns+cAhpHc8Lv7R5JOXbJ4jqS12eO1ku4ruC8ADVbrd/5x7t4nSdnfG4prCUAzNPzcfjPrklTfSdwA\nClfryH/MzMZLUvb3eKUXuvsKd+9w944a3wtAA9Qa/s2SLl4G1ynpnWLaAdAsueE3s/WS/lvSzWZ2\n2MwelfRzSTPNbL+kmdlzAMNI7nd+d59XofSDgnsZtj788MOyWyhN3vkRq1atqnnbTz31VLK+e/fu\nmrd97ty5ZH3NmjXJet59/2+66aZkfbgc5wdwGSL8QFCEHwiK8ANBEX4gKMIPBMWtu1GX+++/P1k3\ns4q1M2fOJNfdtm1bTT2hOoz8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAUx/mRNHr06GR98eLFNW97\n6dKlyfrp0+XdDX7MmDHJeur8heGCkR8IivADQRF+ICjCDwRF+IGgCD8QFOEHguI4P5JuvvnmZH3K\nlCk1b3vLli01r1u2kydPJut9fX1N6qR2jPxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFTucX4zWy1p\ntqTj7n5rtmyRpPmSLs4z/Jy7v9+oJlvdjBkzkvX169c3qZPidXZ21rX+3r17K9aOHDlS17Ybqa2t\nLVnPO45/6NChIttpiGpG/jWS7hlk+b+5++3Zf2GDDwxXueF3948knWpCLwCaqJ7v/E+a2R/MbLWZ\nXVdYRwCaotbwL5c0WdLtkvok/aLSC82sy8x6zKynxvcC0AA1hd/dj7n7BXf/WtJKSdMTr13h7h3u\n3lFrkwCKV1P4zWz8gKc/lrSrmHYANEs1h/rWS7pL0rfN7LCkn0m6y8xul+SSDkp6rIE9AmiA3PC7\n+7xBFq9qQC/D1qRJk8puoWa33XZbsr5gwYK6tr9t27aKtbNnz9a17Xrk3Zf/8ccfT9Z7eob/T1ic\n4QcERfiBoAg/EBThB4Ii/EBQhB8Iilt3Z7Zu3ZqsP/rooxVrU6dOTa47fvz4ZL3M2zxPmzYtWR8x\nIj0+uHuy3t3dPeSemiHvUF97e3uyvmvX8D+vjZEfCIrwA0ERfiAowg8ERfiBoAg/EBThB4KyvOO0\nhb6ZWfPebIhGjhyZrH/88ccVa9OnV7yRkSTp/ffTNze+9957k/VGevPNN5P1J554Iln/6quvkvVR\no0YNuaeijB49umJt48aNyXVnzZqVrOedJ3D69OlkvZHc3ap5HSM/EBThB4Ii/EBQhB8IivADQRF+\nICjCDwTF9fyZvOPVS5YsqVjbsmVLct2ZM2cm6+vWrUvWH3ssPS3CuXPnkvWUvHsR5HnvvffqWr8e\nV199dbK+dOnSirW84/jbt29P1r/44otkfThg5AeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoHKP85vZ\nREnrJH1H0teSVrj7q2Y2RtJvJbVLOijpAXcv7yLmBktdkz9//vzkunnXzD/88MPJet4U4C+99FLF\n2pEjR5Lrpq55r8bnn3+erKfOI9i3b19y3TvuuCNZ37x5c7J+/fXXV6y98cYbyXUXLlyYrF+4cCFZ\nHw6qGfnPS/qpu/+dpH+UtMDM/l7Ss5K2u/sUSduz5wCGidzwu3ufu+/MHp+VtEfSBElzJK3NXrZW\n0n2NahJA8Yb0nd/M2iVNk/SJpHHu3if1/wMh6YaimwPQOFWf229moyVtlLTQ3c+YVXWbMJlZl6Su\n2toD0ChVjfxmNlL9wf+Vu2/KFh8zs/FZfbyk44Ot6+4r3L3D3TuKaBhAMXLDb/1D/CpJe9z9lwNK\nmyV1Zo87Jb1TfHsAGiX31t1m9n1Jv5fUq/5DfZL0nPq/92+Q9F1JhyTNdfdTOdtq2Vt3N1JnZ2ey\nvnjx4mT9xhtvLLKdQp04cSJZHzt2bMVab29vct22trZk/aqrrkrWly1bVrH28ssvJ9fNu8S7lVV7\n6+7c7/zu/rGkShv7wVCaAtA6OMMPCIrwA0ERfiAowg8ERfiBoAg/EBRTdAOXGaboBpBE+IGgCD8Q\nFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/\nEBThB4Ii/EBQhB8IivADQeWG38wmmtl/mtkeM/ujmf1rtnyRmR0xs//J/vtR49sFUJTcSTvMbLyk\n8e6+08y+JWmHpPskPSDpL+7+StVvxqQdQMNVO2nHlVVsqE9SX/b4rJntkTShvvYAlG1I3/nNrF3S\nNEmfZIueNLM/mNlqM7uuwjpdZtZjZj11dQqgUFXP1WdmoyX9l6Rl7r7JzMZJOinJJS1V/1eDf8nZ\nBrv9QINVu9tfVfjNbKSkLZK2uvsvB6m3S9ri7rfmbIfwAw1W2ESdZmaSVknaMzD42Q+BF/1Y0q6h\nNgmgPNX82v99Sb+X1Cvp62zxc5LmSbpd/bv9ByU9lv04mNoWIz/QYIXu9heF8AONV9huP4DLE+EH\ngiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCo3Bt4FuykpP8d8Pzb\n2bJW1Kq9tWpfEr3Vqsjebqz2hU29nv8bb27W4+4dpTWQ0Kq9tWpfEr3Vqqze2O0HgiL8QFBlh39F\nye+f0qq9tWpfEr3VqpTeSv3OD6A8ZY/8AEpSSvjN7B4z22dmB8zs2TJ6qMTMDppZbzbzcKlTjGXT\noB03s10Dlo0xs21mtj/7O+g0aSX11hIzNydmli71s2u1Ga+bvttvZldI+pOkmZIOS/pU0jx3393U\nRiows4OSOty99GPCZvZPkv4iad3F2ZDM7GVJp9z959k/nNe5+zMt0tsiDXHm5gb1Vmlm6X9WiZ9d\nkTNeF6GMkX+6pAPu/pm7/1XSbyTNKaGPlufuH0k6dcniOZLWZo/Xqv9/nqar0FtLcPc+d9+ZPT4r\n6eLM0qV+dom+SlFG+CdI+vOA54fVWlN+u6TfmdkOM+squ5lBjLs4M1L294aS+7lU7szNzXTJzNIt\n89nVMuN10coI/2CzibTSIYfvufs/SPqhpAXZ7i2qs1zSZPVP49Yn6RdlNpPNLL1R0kJ3P1NmLwMN\n0lcpn1sZ4T8saeKA522SjpbQx6Dc/Wj297ikbvV/TWklxy5Okpr9PV5yP//P3Y+5+wV3/1rSSpX4\n2WUzS2+U9Ct335QtLv2zG6yvsj63MsL/qaQpZjbJzEZJ+omkzSX08Q1mdm32Q4zM7FpJs9R6sw9v\nltSZPe6U9E6JvfyNVpm5udLM0ir5s2u1Ga9LOcknO5Tx75KukLTa3Zc1vYlBmNlN6h/tpf4rHn9d\nZm9mtl7SXeq/6uuYpJ9J+g9JGyR9V9IhSXPdvek/vFXo7S4NcebmBvVWaWbpT1TiZ1fkjNeF9MMZ\nfkBMnOEHBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCo/wMv/DhVWUgwlQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febb03118d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = X_test[3846].reshape(-1, 28, 28, 1)\n",
    "plt.imshow(X_test[3846, :, :, 0], cmap='gist_gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_prob",
   "language": "python",
   "name": "tf_prob"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
