{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Neural Networks in Keras and TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u30073/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/glob/intel-python/python3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/u30073/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#TODO: PUT RANDOM SEED FOR RESULT SECURING IN DEMOS\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version (expected = 2.0.0-beta1): 2.0.0-beta1\n",
      "TensorFlow Probability version (expected = 0.9.0-dev20190912): 0.9.0-dev20190912\n"
     ]
    }
   ],
   "source": [
    "print('TensorFlow version (expected = 2.0.0-beta1):', tf.__version__)\n",
    "print('TensorFlow Probability version (expected = 0.9.0-dev20190912):', tfp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X, theta = 1.0, axis = None):\n",
    "    \"\"\"\n",
    "    Compute the softmax of each element along an axis of X.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: ND-Array. Probably should be floats.\n",
    "    theta (optional): float parameter, used as a multiplier\n",
    "        prior to exponentiation. Default = 1.0\n",
    "    axis (optional): axis to compute values along. Default is the\n",
    "        first non-singleton axis.\n",
    "\n",
    "    Returns an array the same size as X. The result will sum to 1\n",
    "    along the specified axis.\n",
    "    \"\"\"\n",
    "\n",
    "    # make X at least 2d\n",
    "    y = np.atleast_2d(X)\n",
    "\n",
    "    # find axis\n",
    "    if axis is None:\n",
    "        axis = next(j[0] for j in enumerate(y.shape) if j[1] > 1)\n",
    "\n",
    "    # multiply y against the theta parameter,\n",
    "    y = y * float(theta)\n",
    "\n",
    "    # subtract the max for numerical stability\n",
    "    y = y - np.expand_dims(np.max(y, axis = axis), axis)\n",
    "\n",
    "    # exponentiate y\n",
    "    y = np.exp(y)\n",
    "\n",
    "    # take the sum along the specified axis\n",
    "    ax_sum = np.expand_dims(np.sum(y, axis = axis), axis)\n",
    "\n",
    "    # finally: divide elementwise\n",
    "    p = y / ax_sum\n",
    "\n",
    "    # flatten if X was 1D\n",
    "    if len(X.shape) == 1: p = p.flatten()\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are all set up, lets go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using MNIST dataset!\n",
      "X_train.shape = (60000, 28, 28, 1)\n",
      "y_train.shape = (60000, 10)\n",
      "X_test.shape = (10000, 28, 28, 1)\n",
      "y_test.shape = (10000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fec1e0446d8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhB8IivADQf0bIHV3m9z7zF4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fec1c248978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "first, we load the dataset. We are trying to do it first with MNIST\n",
    "I've found this snippet somewhere in github\n",
    "\"\"\"\n",
    "\n",
    "#as we have 10 classes, I'm setting class number to 10\n",
    "class_nmr = 10\n",
    "\n",
    "print('We are using MNIST dataset!')\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "n_train = X_train.shape[0]\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, class_nmr)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, class_nmr)\n",
    "\n",
    "# Normalize data\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "print(\"X_train.shape =\", X_train.shape)\n",
    "print(\"y_train.shape =\", y_train.shape)\n",
    "print(\"X_test.shape =\", X_test.shape)\n",
    "print(\"y_test.shape =\", y_test.shape)\n",
    "\n",
    "plt.imshow(X_train[1026, :, :, 0], cmap='gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bayesian_bcnn_model(input_shape):\n",
    "    \n",
    "    \"\"\"\n",
    "    Here we use tf.keras.Model to use our graph as a Neural Network:\n",
    "    We select our input node as the net input, and the last node as our output (predict node).\n",
    "    Note that our model won't be compiled, as we are usign TF2.0 and will optimize it with\n",
    "    a custom @tf.function for loss and a @tf.function for train_step\n",
    "    Our input parameter is just the input shape, a tuple, for the input layer\n",
    "    \"\"\"\n",
    "    \n",
    "    model_in = tf.keras.layers.Input(shape=input_shape)\n",
    "    conv_1 = tfp.python.layers.Convolution2DFlipout(32, kernel_size=(3, 3), padding=\"same\", strides=2)\n",
    "    x = conv_1(model_in)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    conv_2 = tfp.python.layers.Convolution2DFlipout(64, kernel_size=(3, 3), padding=\"same\", strides=2)\n",
    "    x = conv_2(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    dense_1 = tfp.python.layers.DenseFlipout(512, activation='relu')\n",
    "    x = dense_1(x)\n",
    "    dense_2 = tfp.python.layers.DenseFlipout(10, activation=None)\n",
    "    model_out = dense_2(x)  # logits\n",
    "    model = tf.keras.Model(model_in, model_out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "here we are just instancing our model and setting up an Optimizer\n",
    "\"\"\"\n",
    "bcnn = build_bayesian_bcnn_model(X_train.shape[1:])\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this is our loss function: a sum of KL Divergence and Softmax crossentropy\n",
    "We use the @tf.function annotation becuase of TF2.0, and need no placeholders\n",
    "we get each loss and return its mean\n",
    "\"\"\"\n",
    "\n",
    "@tf.function\n",
    "def elbo_loss(labels, logits):\n",
    "    loss_en = tf.nn.softmax_cross_entropy_with_logits(labels, logits)\n",
    "    loss_kl = tf.keras.losses.KLD(labels, logits)\n",
    "    loss = tf.reduce_mean(tf.add(loss_en, loss_kl))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this is our train step with tf2.0, very ellegant:\n",
    "We do our flow of the tensors over the model recording its gradientes\n",
    "Then, our gradient tape to give us a list of the gradients of each parameter in relation of the loss\n",
    "we dan ask our previously instanced optimizer to apply those gradients to the variable\n",
    "It is cool to see that it works even with TensorFlow probability- probabilistic layers parameters\n",
    "\"\"\"\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = bcnn(X_train)\n",
    "        loss = elbo_loss(labels, logits)\n",
    "    gradients = tape.gradient(loss, bcnn.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, bcnn.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "def accuracy(preds, labels):\n",
    "    return np.mean(np.argmax(preds, axis=1) == np.argmax(y_train, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0913 05:31:02.271690 140654324322048 deprecation.py:323] From /home/u30073/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0: loss = 10.747198104858398 , accuracy = 0.1064\n",
      "Epoch: 1: loss = 23.540878295898438 , accuracy = 0.16245\n",
      "Epoch: 2: loss = 19.142011642456055 , accuracy = 0.17528333333333335\n",
      "Epoch: 3: loss = 19.116121292114258 , accuracy = 0.16303333333333334\n",
      "Epoch: 4: loss = 15.79915714263916 , accuracy = 0.18071666666666666\n",
      "Epoch: 5: loss = 9.62914752960205 , accuracy = 0.19285\n",
      "Epoch: 6: loss = 6.188024044036865 , accuracy = 0.1813\n",
      "Epoch: 7: loss = 3.628391742706299 , accuracy = 0.20343333333333333\n",
      "Epoch: 8: loss = 2.5465056896209717 , accuracy = 0.23295\n",
      "Epoch: 9: loss = 2.2185027599334717 , accuracy = 0.33235\n",
      "Epoch: 10: loss = 2.1773431301116943 , accuracy = 0.36588333333333334\n",
      "Epoch: 11: loss = 2.179811954498291 , accuracy = 0.4036\n",
      "Epoch: 12: loss = 2.0477283000946045 , accuracy = 0.4649\n",
      "Epoch: 13: loss = 1.8958021402359009 , accuracy = 0.5295166666666666\n",
      "Epoch: 14: loss = 1.6953232288360596 , accuracy = 0.5753166666666667\n",
      "Epoch: 15: loss = 1.4486218690872192 , accuracy = 0.6251833333333333\n",
      "Epoch: 16: loss = 1.2544399499893188 , accuracy = 0.6524666666666666\n",
      "Epoch: 17: loss = 1.009433388710022 , accuracy = 0.6436666666666667\n",
      "Epoch: 18: loss = 1.0323320627212524 , accuracy = 0.7112166666666667\n",
      "Epoch: 19: loss = 0.8931180834770203 , accuracy = 0.7318333333333333\n",
      "Epoch: 20: loss = 0.8660682439804077 , accuracy = 0.7646333333333334\n",
      "Epoch: 21: loss = 0.8000099062919617 , accuracy = 0.78865\n",
      "Epoch: 22: loss = 0.7186559438705444 , accuracy = 0.7952833333333333\n",
      "Epoch: 23: loss = 0.6536609530448914 , accuracy = 0.8178\n",
      "Epoch: 24: loss = 0.6013283729553223 , accuracy = 0.8266333333333333\n",
      "Epoch: 25: loss = 0.5560389161109924 , accuracy = 0.8377166666666667\n",
      "Epoch: 26: loss = 0.5262611508369446 , accuracy = 0.8434\n",
      "Epoch: 27: loss = 0.4979460835456848 , accuracy = 0.8583\n",
      "Epoch: 28: loss = 0.463104784488678 , accuracy = 0.8665\n",
      "Epoch: 29: loss = 0.44907090067863464 , accuracy = 0.8778\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    loss = train_step(X_train, y_train)\n",
    "    preds = bcnn(X_train)\n",
    "    acc = accuracy(preds, y_train)\n",
    "    print(\"Epoch: {}: loss = {} , accuracy = {}\".format(i, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of recognizable samples: 9995\n",
      "Unrecognizable samples: [2488 3757 3846 4761 5735]\n",
      "Test accuracy on MNIST (recognizable samples): 0.8938469234617309\n",
      "Test accuracy on MNIST (unrecognizable samples): 0.0\n"
     ]
    }
   ],
   "source": [
    "n_mc_run = 50\n",
    "med_prob_thres = 0.20\n",
    "\n",
    "y_pred_logits_list = [bcnn(X_test) for _ in range(n_mc_run)]  # a list of predicted logits\n",
    "y_pred_prob_all = np.concatenate([softmax(y, axis=-1)[:, :, np.newaxis] for y in y_pred_logits_list], axis=-1)\n",
    "y_pred = [[int(np.median(y) >= med_prob_thres) for y in y_pred_prob] for y_pred_prob in y_pred_prob_all]\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "idx_valid = [any(y) for y in y_pred]\n",
    "print('Number of recognizable samples:', sum(idx_valid))\n",
    "\n",
    "idx_invalid = [not any(y) for y in y_pred]\n",
    "print('Unrecognizable samples:', np.where(idx_invalid)[0])\n",
    "\n",
    "print('Test accuracy on MNIST (recognizable samples):',\n",
    "      sum(np.equal(np.argmax(y_test[idx_valid], axis=-1), np.argmax(y_pred[idx_valid], axis=-1))) / len(y_test[idx_valid]))\n",
    "\n",
    "print('Test accuracy on MNIST (unrecognizable samples):',\n",
    "      sum(np.equal(np.argmax(y_test[idx_invalid], axis=-1), np.argmax(y_pred[idx_invalid], axis=-1))) / len(y_test[idx_invalid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7febb024b828>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febb03118d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = X_test[3846].reshape(-1, 28, 28, 1)\n",
    "plt.imshow(X_test[3846, :, :, 0], cmap='gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfp_nightly",
   "language": "python",
   "name": "tfp_nightly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
