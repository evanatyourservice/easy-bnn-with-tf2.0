{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Neural Networks in Keras and TensorFlow 1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: PUT RANDOM SEED FOR RESULT SECURING IN DEMOS\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version (expected = 1.14.0): 1.14.0\n",
      "TensorFlow Probability version (expected = 0.9.0-dev20190912): 0.7.0\n"
     ]
    }
   ],
   "source": [
    "print('TensorFlow version (expected = 1.14.0):', tf.__version__)\n",
    "print('TensorFlow Probability version (expected = 0.9.0-dev20190912):', tfp.__version__)\n",
    "#trying to make it work with this version, as the nightly one does not import here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X, theta = 1.0, axis = None):\n",
    "    \"\"\"\n",
    "    Compute the softmax of each element along an axis of X.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: ND-Array. Probably should be floats.\n",
    "    theta (optional): float parameter, used as a multiplier\n",
    "        prior to exponentiation. Default = 1.0\n",
    "    axis (optional): axis to compute values along. Default is the\n",
    "        first non-singleton axis.\n",
    "\n",
    "    Returns an array the same size as X. The result will sum to 1\n",
    "    along the specified axis.\n",
    "    \"\"\"\n",
    "\n",
    "    # make X at least 2d\n",
    "    y = np.atleast_2d(X)\n",
    "\n",
    "    # find axis\n",
    "    if axis is None:\n",
    "        axis = next(j[0] for j in enumerate(y.shape) if j[1] > 1)\n",
    "\n",
    "    # multiply y against the theta parameter,\n",
    "    y = y * float(theta)\n",
    "\n",
    "    # subtract the max for numerical stability\n",
    "    y = y - np.expand_dims(np.max(y, axis = axis), axis)\n",
    "\n",
    "    # exponentiate y\n",
    "    y = np.exp(y)\n",
    "\n",
    "    # take the sum along the specified axis\n",
    "    ax_sum = np.expand_dims(np.sum(y, axis = axis), axis)\n",
    "\n",
    "    # finally: divide elementwise\n",
    "    p = y / ax_sum\n",
    "\n",
    "    # flatten if X was 1D\n",
    "    if len(X.shape) == 1: p = p.flatten()\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are all set up, lets go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using MNIST dataset!\n",
      "X_train.shape = (60000, 28, 28, 1)\n",
      "y_train.shape = (60000, 10)\n",
      "X_test.shape = (10000, 28, 28, 1)\n",
      "y_test.shape = (10000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe8ec909f98>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhB8IivADQf0bIHV3m9z7zF4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe8ec94a588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "first, we load the dataset. We are trying to do it first with MNIST\n",
    "I've found this snippet somewhere in github\n",
    "\"\"\"\n",
    "\n",
    "#as we have 10 classes, I'm setting class number to 10\n",
    "class_nmr = 10\n",
    "\n",
    "print('We are using MNIST dataset!')\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "n_train = X_train.shape[0]\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, class_nmr)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, class_nmr)\n",
    "\n",
    "# Normalize data\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "print(\"X_train.shape =\", X_train.shape)\n",
    "print(\"y_train.shape =\", y_train.shape)\n",
    "print(\"X_test.shape =\", X_test.shape)\n",
    "print(\"y_test.shape =\", y_test.shape)\n",
    "\n",
    "plt.imshow(X_train[1026, :, :, 0], cmap='gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCNN:\n",
    "    def __init__(self):\n",
    "        self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        self.model_in = tf.placeholder(shape=[None,28,28,1], dtype=\"float32\")\n",
    "        self.labels = tf.placeholder(shape=[None,10], dtype=\"float32\")\n",
    "        \n",
    "        self.conv_1 = tfp.python.layers.Convolution2DFlipout(32, kernel_size=(3, 3), padding=\"same\", strides=2)\n",
    "        self.x = self.conv_1(self.model_in)\n",
    "        self.x = tf.keras.layers.BatchNormalization()(self.x)\n",
    "        self.x = tf.keras.layers.Activation('relu')(self.x)\n",
    "        self.conv_2 = tfp.python.layers.Convolution2DFlipout(64, kernel_size=(3, 3), padding=\"same\", strides=2)\n",
    "        self.x = self.conv_2(self.x)\n",
    "        self.x = tf.keras.layers.BatchNormalization()(self.x)\n",
    "        self.x = tf.keras.layers.Activation('relu')(self.x)\n",
    "        self.x = tf.keras.layers.Flatten()(self.x)\n",
    "        self.dense_1 = tfp.python.layers.DenseFlipout(512, activation='relu')\n",
    "        self.x = self.dense_1(self.x)\n",
    "        self.dense_2 = tfp.python.layers.DenseFlipout(10, activation=None)\n",
    "        self.preds = self.dense_2(self.x)  # logits\n",
    "        \n",
    "        self.loss_en = tf.nn.softmax_cross_entropy_with_logits(labels=self.labels, logits=self.preds)\n",
    "        self.loss_kl = tf.keras.losses.KLD(self.labels, self.preds) \n",
    "        self.loss = tf.reduce_mean(tf.add(self.loss_en, self.loss_kl))\n",
    "\n",
    "        self.optimizer = tf.train.AdamOptimizer(0.01)\n",
    "        self.train_op = self.optimizer.minimize(self.loss)\n",
    "        \n",
    "    def predict(self, sess, X):\n",
    "        return sess.run(self.preds, { self.model_in: X })\n",
    "    \n",
    "    def update(self, sess, x, y):\n",
    "        feed_dict = { self.model_in: x, self.labels: y }\n",
    "        _, loss = sess.run(\n",
    "            [self.train_op, self.loss],\n",
    "            feed_dict)\n",
    "        return loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcnn = BCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22: loss = 9.74981689453125 , accuracy = 0.13398333333333334\n",
      "Epoch: 23: loss = 15.528031349182129 , accuracy = 0.14601666666666666\n",
      "Epoch: 24: loss = 8.114693641662598 , accuracy = 0.14813333333333334\n",
      "Epoch: 25: loss = 6.095821857452393 , accuracy = 0.1594\n",
      "Epoch: 26: loss = 4.190555095672607 , accuracy = 0.11913333333333333\n",
      "Epoch: 27: loss = 4.154258728027344 , accuracy = 0.11366666666666667\n",
      "Epoch: 28: loss = 3.0169458389282227 , accuracy = 0.11581666666666666\n",
      "Epoch: 29: loss = 2.598907709121704 , accuracy = 0.1232\n",
      "Epoch: 30: loss = 2.406958818435669 , accuracy = 0.13351666666666667\n",
      "Epoch: 31: loss = 2.3748056888580322 , accuracy = 0.13823333333333335\n",
      "Epoch: 32: loss = 2.3856494426727295 , accuracy = 0.1404\n",
      "Epoch: 33: loss = 2.454460382461548 , accuracy = 0.15533333333333332\n",
      "Epoch: 34: loss = 2.3139593601226807 , accuracy = 0.17203333333333334\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:   \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(20):\n",
    "        loss = bcnn.update(x=X_train, sess=sess, y=y_train)\n",
    "        #print(loss)\n",
    "        preds = bcnn.predict(sess, X_train)\n",
    "        acc = accuracy(preds, y_train)\n",
    "        print(\"Epoch: {}: loss = {} , accuracy = {}\".format(i, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'input_1:0' shape=(?, 28, 28, 1) dtype=float32>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcnn.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def elbo_loss(labels, logits):\n",
    "    loss_en = tf.nn.softmax_cross_entropy_with_logits(labels, logits)\n",
    "    loss_kl = tf.keras.losses.KLD(y_train, logits)\n",
    "    loss = tf.reduce_mean(tf.add(loss_en, loss_kl))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images, labels, optimizer, model):\n",
    "    \n",
    "    logits = model(images)\n",
    "    loss = elbo_loss(labels, logits)\n",
    "    optimizer.minimize(loss)\n",
    "    return loss\n",
    "\n",
    "def accuracy(preds, labels):\n",
    "    return np.mean(np.argmax(preds, axis=1) == np.argmax(y_train, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of recognizable samples: 9998\n",
      "Unrecognizable samples: [5891 6706]\n",
      "Test accuracy on MNIST (recognizable samples): 0.9275855171034206\n",
      "Test accuracy on MNIST (unrecognizable samples): 0.0\n"
     ]
    }
   ],
   "source": [
    "n_mc_run = 50\n",
    "med_prob_thres = 0.20\n",
    "\n",
    "y_pred_logits_list = [bcnn(X_test) for _ in range(n_mc_run)]  # a list of predicted logits\n",
    "y_pred_prob_all = np.concatenate([softmax(y, axis=-1)[:, :, np.newaxis] for y in y_pred_logits_list], axis=-1)\n",
    "y_pred = [[int(np.median(y) >= med_prob_thres) for y in y_pred_prob] for y_pred_prob in y_pred_prob_all]\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "idx_valid = [any(y) for y in y_pred]\n",
    "print('Number of recognizable samples:', sum(idx_valid))\n",
    "\n",
    "idx_invalid = [not any(y) for y in y_pred]\n",
    "print('Unrecognizable samples:', np.where(idx_invalid)[0])\n",
    "\n",
    "print('Test accuracy on MNIST (recognizable samples):',\n",
    "      sum(np.equal(np.argmax(y_test[idx_valid], axis=-1), np.argmax(y_pred[idx_valid], axis=-1))) / len(y_test[idx_valid]))\n",
    "\n",
    "print('Test accuracy on MNIST (unrecognizable samples):',\n",
    "      sum(np.equal(np.argmax(y_test[idx_invalid], axis=-1), np.argmax(y_pred[idx_invalid], axis=-1))) / len(y_test[idx_invalid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7ad837ac18>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7ad83f8240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = X_train[5891].reshape(-1, 28, 28, 1)\n",
    "plt.imshow(X_train[5891, :, :, 0], cmap='gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1_bnn",
   "language": "python",
   "name": "tf1_bnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
